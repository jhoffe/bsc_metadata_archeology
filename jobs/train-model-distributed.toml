queue = "gpua100"
name = "train-model"
walltime = { hours = 16, minutes = 0 }
cpu = 24
memory = 8
standard_output = { name = "logs/train-model.out", overwrite = true }
error_output = { name = "logs/train-model.err", overwrite = true }
use_gpu = { num_of_gpus = 2 }
core_p_tile_size = 8

commands = [
    "module load python3/3.10.7",
    "module load cuda/11.7",
    "module load mpi4py/3.1.3-python-3.10.7-openmpi-4.1.4",
    "source venv/bin/activate",
    "export CUDA_VISIBLE_DEVICES=0,1",
    "mpirun -np 6 -x MASTER_ADDR=$(HOSTNAME) -x MASTER_PORT=29400 -x PATH -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib python3 src/models/train_model.py training=hpc-distributed"
]
